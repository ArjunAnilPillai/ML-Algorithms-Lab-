{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML Lab 9",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfD7rQbEaDbu"
      },
      "source": [
        "#Name - Arjun A.\n",
        "#Roll number - 181CO109\n",
        "#Date of submission - 19-3-2021\n",
        "This notebook was written in google colab. <br>Link to view notebook<br>\n",
        "https://colab.research.google.com/drive/1mwYxrMaSh79F-_-qWt6lN0ysPnJvCUEt?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpZRvlqrLM1g"
      },
      "source": [
        "#ML Lab 9 - Logistic Regression\n",
        "This notebook is used to implement Logistic Regression to do classification. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfmdtJRBik33"
      },
      "source": [
        "##Importing necessary packages\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3B4W9XOzgc1V"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSNguicKSUhY"
      },
      "source": [
        "##Importing data from the iris dataset\n",
        "Using the load_iris function from sklearn, importing the iris dataset\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoAjKGwRPLYH"
      },
      "source": [
        "# Function to import data\n",
        "def importdata(): \n",
        "\n",
        "  irisData = load_iris()\n",
        "  X = irisData.data\n",
        "  Y = irisData.target\n",
        "  names = irisData.target_names\n",
        "  featureName = irisData.feature_names\n",
        "  print(type(X))\n",
        "  print(type(Y))\n",
        "  print(names)\n",
        "  \n",
        "  return X, Y, names, featureName"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtJPFJ3wSwUf",
        "outputId": "dd8d3feb-80af-4b1a-9d0b-d75cb6cde83e"
      },
      "source": [
        "X, Y, irisClassNames, irisFeatureNames = importdata()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "['setosa' 'versicolor' 'virginica']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CO4D9ViCWO9h"
      },
      "source": [
        "##Splitting the data into train and test sets\n",
        " Splitting the data in the ratio of 7:3. (70% training and 30% testing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBOcVcrbXZoa"
      },
      "source": [
        "def splitdataset(X, Y): \n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 100) #Specifying random_state to get the same dataset split everytime \n",
        "\t\n",
        "  return X, Y, X_train, X_test, y_train, y_test "
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xq7whDXkZyyv",
        "outputId": "b429d36a-8e3f-4beb-83f7-f03f807d2aec"
      },
      "source": [
        "X, Y, X_train, X_test, y_train, y_test = splitdataset(X, Y)\n",
        "\n",
        "#Use to print the entire dataset\n",
        "#print(X, Y, X_train, X_test, y_train, y_test, sep = '\\n\\n')\n",
        "\n",
        "#Printing size of the split\n",
        "print('Test dataset size\\nX_test -', len(X_test), '\\ny_test -', len(y_test), '\\n')\n",
        "print('Train dataset size\\nX_train -', len(X_train), '\\ny_train -', len(y_train))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test dataset size\n",
            "X_test - 45 \n",
            "y_test - 45 \n",
            "\n",
            "Train dataset size\n",
            "X_train - 105 \n",
            "y_train - 105\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5u0J-8TuKP9"
      },
      "source": [
        "## Defining model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SzaujyvuN4W"
      },
      "source": [
        "logRegression = LogisticRegression(max_iter= 1000)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYNwLaAGsRyG"
      },
      "source": [
        "##Training model on train dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0J9EG4LlCWS",
        "outputId": "4f5bfce0-ca98-46f9-9b6d-5b36323c1c7d"
      },
      "source": [
        "logRegression.fit(X_train,y_train)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0Xq05DHlFHw"
      },
      "source": [
        "##Calculating accuracy on the model using the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmSMcDHWlMS9",
        "outputId": "2fbf0047-6c3e-4c6d-f760-7d8360adab1d"
      },
      "source": [
        "y_pred = logRegression.predict(X_test)\n",
        "print('Accuracy =',logRegression.score(X_test,y_test), '\\n')\n",
        "print('Confusion Matrix\\n')\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print('\\nClassification report\\n')\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy = 0.9777777777777777 \n",
            "\n",
            "Confusion Matrix\n",
            "\n",
            "[[16  0  0]\n",
            " [ 0 11  0]\n",
            " [ 0  1 17]]\n",
            "\n",
            "Classification report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        16\n",
            "           1       0.92      1.00      0.96        11\n",
            "           2       1.00      0.94      0.97        18\n",
            "\n",
            "    accuracy                           0.98        45\n",
            "   macro avg       0.97      0.98      0.98        45\n",
            "weighted avg       0.98      0.98      0.98        45\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}