{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_lab_3",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfD7rQbEaDbu"
      },
      "source": [
        "#Name - Arjun A.\r\n",
        "#Roll number - 181CO109\r\n",
        "#Date of submission - 29-01-2021\r\n",
        "This notebook was written in google colab. <br>Link to view notebook<br>\r\n",
        "https://colab.research.google.com/drive/1_-rzD-sKIOuno0RNcMg96GuXw5JQKKC8?usp=sharing\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_XaWBJeZ_RD"
      },
      "source": [
        "#Machine Learning Lab 3\r\n",
        "To demonstrate the usage of a naive Bayes classifier for a sample dataset. This is a classifier based on Bayes theorom. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwC5ZiTebH-P"
      },
      "source": [
        "##Installing and Importing required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8Loq4nKZ8Pu",
        "outputId": "8ce99c1b-4d48-4b80-b783-c2ab7aed9604"
      },
      "source": [
        "!pip install numpy\r\n",
        "!pip install scipy\r\n",
        "!pip install -U scikit-learn\r\n",
        "!pip install pandas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.19.5)\n",
            "Requirement already up-to-date: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.24.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (2.1.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDPqimOjbQwW"
      },
      "source": [
        "import numpy as np \r\n",
        "import pandas as pd \r\n",
        "from sklearn.model_selection import train_test_split \r\n",
        "from sklearn.naive_bayes import GaussianNB\r\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\r\n",
        "from sklearn.datasets import load_iris"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSNguicKSUhY"
      },
      "source": [
        "##Importing data from the iris dataset\r\n",
        "Using the load_iris function from sklearn, importing the iris dataset\r\n",
        "\r\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoAjKGwRPLYH"
      },
      "source": [
        "# Function to import data\r\n",
        "def importdata(): \r\n",
        "\r\n",
        "  irisData = load_iris()\r\n",
        "  X = irisData.data\r\n",
        "  Y = irisData.target\r\n",
        "  names = irisData.target_names\r\n",
        "  featureName = irisData.feature_names\r\n",
        "  print(type(X))\r\n",
        "  print(type(Y))\r\n",
        "  print(names)\r\n",
        "  \r\n",
        "  return X, Y, names, featureName"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtJPFJ3wSwUf",
        "outputId": "5141f37f-9fec-4d1d-a444-2b27fc99b221"
      },
      "source": [
        "X, Y, irisClassNames, irisFeatureNames = importdata()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "['setosa' 'versicolor' 'virginica']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBkxAJfkby4j"
      },
      "source": [
        "##Splitting the data into train and test sets\r\n",
        " Splitting the data in the ratio of 7:3. (70% training and 30% testing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBOcVcrbXZoa"
      },
      "source": [
        "def splitdataset(X, Y): \r\n",
        "\r\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 100) #Specifying random_state to get the same dataset split everytime \r\n",
        "\t\r\n",
        "  return X, Y, X_train, X_test, y_train, y_test "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xq7whDXkZyyv",
        "outputId": "283e2c69-7b95-48bd-8f8b-063551b81150"
      },
      "source": [
        "X, Y, X_train, X_test, y_train, y_test = splitdataset(X, Y)\r\n",
        "\r\n",
        "#Use to print the entire dataset\r\n",
        "#print(X, Y, X_train, X_test, y_train, y_test, sep = '\\n\\n')\r\n",
        "\r\n",
        "#Printing size of the split\r\n",
        "print('Test dataset size\\nX_test -', len(X_test), '\\ny_test -', len(y_test), '\\n')\r\n",
        "print('Train dataset size\\nX_train -', len(X_train), '\\ny_train -', len(y_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test dataset size\n",
            "X_test - 45 \n",
            "y_test - 45 \n",
            "\n",
            "Train dataset size\n",
            "X_train - 105 \n",
            "y_train - 105\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIDjWafMpodX"
      },
      "source": [
        "##Function to measure accuracy \r\n",
        "Using sklearn's classification_report, confusion_matrix and accuracy_score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmAxi_cZp8F2"
      },
      "source": [
        "def measuringAccuracy(y_test, y_predict):\r\n",
        "  print('Accuracy -', (accuracy_score(y_test, y_predict) * 100))\r\n",
        "  print('Report', classification_report(y_test, y_predict), sep = '\\n')\r\n",
        "  print('\\nConfusion matrix\\n', confusion_matrix(y_test, y_predict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1dw6F-ksUiU"
      },
      "source": [
        "##Training the model on training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EexJkxsIsADK",
        "outputId": "4e4e82e0-290c-4090-cdb7-cc604358b692"
      },
      "source": [
        "model = GaussianNB() \n",
        "model.fit(X_train, y_train) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVXJVVVgsgr7"
      },
      "source": [
        "##Calculating the accuracy of the model\n",
        "The accuracy of the model is calculated based on the test data. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vewcVdSpsOhN",
        "outputId": "ec0bb9d2-606f-4692-9911-9dcfa84a99eb"
      },
      "source": [
        "y_pred = model.predict(X_test)\r\n",
        "measuringAccuracy(y_test, y_pred)\r\n",
        "print('', 'Class Names of the iris dataset', irisClassNames, '', 'Feature Names of the iris dataset', irisFeatureNames, sep = '\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy - 95.55555555555556\n",
            "Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        16\n",
            "           1       0.91      0.91      0.91        11\n",
            "           2       0.94      0.94      0.94        18\n",
            "\n",
            "    accuracy                           0.96        45\n",
            "   macro avg       0.95      0.95      0.95        45\n",
            "weighted avg       0.96      0.96      0.96        45\n",
            "\n",
            "\n",
            "Confusion matrix\n",
            " [[16  0  0]\n",
            " [ 0 10  1]\n",
            " [ 0  1 17]]\n",
            "\n",
            "Class Names of the iris dataset\n",
            "['setosa' 'versicolor' 'virginica']\n",
            "\n",
            "Feature Names of the iris dataset\n",
            "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}