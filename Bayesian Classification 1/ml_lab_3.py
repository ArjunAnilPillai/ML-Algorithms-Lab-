# -*- coding: utf-8 -*-
"""ML_lab_3

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_-rzD-sKIOuno0RNcMg96GuXw5JQKKC8

#Name - Arjun A.
#Roll number - 181CO109
#Date of submission - 29-01-2021
This notebook was written in google colab. <br>Link to view notebook<br>
https://colab.research.google.com/drive/1_-rzD-sKIOuno0RNcMg96GuXw5JQKKC8?usp=sharing

#Machine Learning Lab 3
To demonstrate the usage of a naive Bayes classifier for a sample dataset. This is a classifier based on Bayes theorom.

##Installing and Importing required packages
"""

!pip install numpy
!pip install scipy
!pip install -U scikit-learn
!pip install pandas

import numpy as np 
import pandas as pd 
from sklearn.model_selection import train_test_split 
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.datasets import load_iris

"""##Importing data from the iris dataset
Using the load_iris function from sklearn, importing the iris dataset

https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris
"""

# Function to import data
def importdata(): 

  irisData = load_iris()
  X = irisData.data
  Y = irisData.target
  names = irisData.target_names
  featureName = irisData.feature_names
  print(type(X))
  print(type(Y))
  print(names)
  
  return X, Y, names, featureName

X, Y, irisClassNames, irisFeatureNames = importdata()

"""##Splitting the data into train and test sets
 Splitting the data in the ratio of 7:3. (70% training and 30% testing)
"""

def splitdataset(X, Y): 

  X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 100) #Specifying random_state to get the same dataset split everytime 
	
  return X, Y, X_train, X_test, y_train, y_test

X, Y, X_train, X_test, y_train, y_test = splitdataset(X, Y)

#Use to print the entire dataset
#print(X, Y, X_train, X_test, y_train, y_test, sep = '\n\n')

#Printing size of the split
print('Test dataset size\nX_test -', len(X_test), '\ny_test -', len(y_test), '\n')
print('Train dataset size\nX_train -', len(X_train), '\ny_train -', len(y_train))

"""##Function to measure accuracy 
Using sklearn's classification_report, confusion_matrix and accuracy_score.
"""

def measuringAccuracy(y_test, y_predict):
  print('Accuracy -', (accuracy_score(y_test, y_predict) * 100))
  print('Report', classification_report(y_test, y_predict), sep = '\n')
  print('\nConfusion matrix\n', confusion_matrix(y_test, y_predict))

"""##Training the model on training set"""

model = GaussianNB() 
model.fit(X_train, y_train)

"""##Calculating the accuracy of the model
The accuracy of the model is calculated based on the test data. 


"""

y_pred = model.predict(X_test)
measuringAccuracy(y_test, y_pred)
print('', 'Class Names of the iris dataset', irisClassNames, '', 'Feature Names of the iris dataset', irisFeatureNames, sep = '\n')